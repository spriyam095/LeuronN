{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EmotionRecognizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spriyam095/LeuronN/blob/master/Speech%20Emotion%20Recogniser/EmotionRecognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjyJm91SEG5l",
        "colab_type": "text"
      },
      "source": [
        "#                 **SPEECH EMOTION RECOGNITON**\n",
        "\n",
        "Speech emotion recognition is a simple Python mini-project, which we are going to practice. But before we go further we need to install a library(***soundfile***) to operate with our audio files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmqWedQAG_f2",
        "colab_type": "code",
        "outputId": "eeacfc51-dde4-43d0-a453-fad8b23aee26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "pip install soundfile "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.13.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.19)\n",
            "Installing collected packages: soundfile\n",
            "Successfully installed soundfile-0.10.3.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QNFbBsUE-OK",
        "colab_type": "text"
      },
      "source": [
        "And because at the start of the Model I faced certain problems with sklearn_version 0.20+... . Therefore I got rid of it and went further with sklearn_version 0.19.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y9tyu1Fj_VN",
        "colab_type": "code",
        "outputId": "5a8882d0-6e76-4f8a-ce98-1af59b3bec51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "pip uninstall sklearn"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling sklearn-0.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/sklearn-0.0.dist-info/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled sklearn-0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIOJ1jTwkGJB",
        "colab_type": "code",
        "outputId": "95eb23ae-a193-4744-deb7-e0b49a0a2043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "pip install scikit-learn==0.19.1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn==0.19.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/2d/9fbc7baa5f44bc9e88ffb7ed32721b879bfa416573e85031e16f52569bc9/scikit_learn-0.19.1-cp36-cp36m-manylinux1_x86_64.whl (12.4MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4MB 178kB/s \n",
            "\u001b[31mERROR: yellowbrick 0.9.1 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imbalanced-learn 0.4.3 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Found existing installation: scikit-learn 0.21.3\n",
            "    Uninstalling scikit-learn-0.21.3:\n",
            "      Successfully uninstalled scikit-learn-0.21.3\n",
            "Successfully installed scikit-learn-0.19.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogLWMl7qFZ7i",
        "colab_type": "text"
      },
      "source": [
        "Now we import necessary libraries. I discovered two new libraries in making this project. **Glob** and **Soundfile**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcOi_3MOJeZt",
        "colab_type": "code",
        "outputId": "314185e0-91c5-49d5-f3ae-46cd044f305a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import librosa\n",
        "import soundfile\n",
        "import glob , os , pickle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import sklearn\n",
        "print(sklearn.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.19.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJymkSH7F3VM",
        "colab_type": "text"
      },
      "source": [
        "Now here I mount my google drive to access my dataset to train on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz2NiibyKfKD",
        "colab_type": "code",
        "outputId": "82841232-dc74-4883-869c-30153115167a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWqFGmu-GCdN",
        "colab_type": "text"
      },
      "source": [
        "Further below is the code to **extract features of those audios** whose emotions are mentioned in the dictionary further below in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4kBYzzpLIrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Extract features (mfcc, chroma, mel) from a sound file\n",
        "\n",
        "def extract_feature(file_name, mfcc, chroma, mel):\n",
        "\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate=sound_file.samplerate\n",
        "        if chroma:\n",
        "            stft=np.abs(librosa.stft(X))\n",
        "        result=np.array([])\n",
        "        if mfcc:\n",
        "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "            result=np.hstack((result, mfccs))\n",
        "        if chroma:\n",
        "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "            result=np.hstack((result, chroma))\n",
        "        if mel:\n",
        "            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "            result=np.hstack((result, mel))\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtS72DQfL4iY",
        "colab_type": "text"
      },
      "source": [
        "Here we Initialize our **Dictionaries**. One may add any emotion from **Dict:** *emotions* to **Dict:** *observed_emotions*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNkG27JgVbM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Emotions in the RAVDESS dataset\n",
        "\n",
        "emotions={\n",
        "  '01':'neutral',\n",
        "  '02':'calm',\n",
        "  '03':'happy',\n",
        "  '04':'sad',\n",
        "  '05':'angry',\n",
        "  '06':'fearful',\n",
        "  '07':'disgust',\n",
        "  '08':'surprised'\n",
        "}\n",
        "#Emotions to observe\n",
        "observed_emotions=['calm', 'happy', 'fearful', 'disgust']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucLzDbc8MgP2",
        "colab_type": "text"
      },
      "source": [
        "Now, let’s load the data with a function load_data() – this takes in the relative size of the test set as parameter. x and y are empty lists; we’ll use the glob() function from the glob module to get all the pathnames for the sound files in our dataset. The pattern we use for this is: “/content/gdrive/My Drive/Colab Notebooks/Emotionaudio/Actor_*/*.wav” as we are importing it from my google drive and **our dataset looks like this**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foINLyI2VSYB",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://d2h0cx97tjks2p.cloudfront.net/blogs/wp-content/uploads/sites/2/2019/09/dataset-simple-python-project.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZR4kV07P7mA",
        "colab_type": "text"
      },
      "source": [
        "So, for each such path, we get the basename of the file, the emotion by splitting the name around ‘-’ and extracting the third value:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6gyzFPEVVP4",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://d2h0cx97tjks2p.cloudfront.net/blogs/wp-content/uploads/sites/2/2019/09/dataset-2-interesting-python-projects.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-Fz-y-TQKe4",
        "colab_type": "text"
      },
      "source": [
        "Using our emotions dictionary, this number is turned into an emotion, and our function checks whether this emotion is in our list of observed_emotions; if not, it continues to the next file. It makes a call to extract_feature and stores what is returned in ‘feature’. Then, it appends the feature to x and the emotion to y. So, the list x holds the features and y holds the emotions. We call the function train_test_split with these, the test size, and a random state value, and return that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6BJyHSnaVah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load the data and extract features for each sound file\n",
        "\n",
        "def load_data(test_size=0.2):\n",
        "\n",
        "    x,y=[],[]\n",
        "\n",
        "    for file in glob.glob(\"/content/gdrive/My Drive/Colab Notebooks/Emotionaudio/Actor_*/*.wav\"):\n",
        "      \n",
        "        file_name=os.path.basename(file)\n",
        "        emotion=emotions[file_name.split(\"-\")[2]]\n",
        "\n",
        "        if emotion not in observed_emotions:\n",
        "            continue\n",
        "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
        "        x.append(feature)\n",
        "        y.append(emotion)\n",
        "\n",
        "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIfmcidpNR-n",
        "colab_type": "text"
      },
      "source": [
        "Time to split the dataset into training and testing sets! Let’s keep the test set 20% of everything and use the load_data function for this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqRAISJJcAxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DataFlair - Split the dataset\n",
        "x_train,x_test,y_train,y_test=load_data(test_size=0.20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nyjka0nSNbEE",
        "colab_type": "text"
      },
      "source": [
        "Next we check the shapes of our train and test respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIjPrJYlcDgt",
        "colab_type": "code",
        "outputId": "1f8678b1-04fc-47c4-9fd6-96a7299bc4b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Get the shape of the training and testing datasets\n",
        "print((x_train.shape[0], x_test.shape[0]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(614, 154)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIMj58gbNjFo",
        "colab_type": "text"
      },
      "source": [
        "Now we see number of features each audio has to be studied."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qhmqb3TsbHNg",
        "colab_type": "code",
        "outputId": "dd4314b3-9f2d-4a80-baab-1685b4b3c65d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Get the number of features extracted\n",
        "print(f'Features extracted: {x_train.shape[1]}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features extracted: 180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLMUN5jbNokk",
        "colab_type": "text"
      },
      "source": [
        "Now, let’s initialize an MLPClassifier. This is a Multi-layer Perceptron Classifier; it optimizes the log-loss function using LBFGS or stochastic gradient descent. Unlike SVM or Naive Bayes, the MLPClassifier has an internal neural network for the purpose of classification. This is a feedforward ANN model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT6Gy38lhEMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize the Multi Layer Perceptron Classifier\n",
        "model=MLPClassifier(alpha=0.01, batch_size=230, epsilon=1e-08, hidden_layer_sizes=(280,), learning_rate='adaptive', max_iter=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqXxCD69Nw5R",
        "colab_type": "text"
      },
      "source": [
        "Next we train it on our training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjKXN2JqhK5P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "070df940-9972-4d91-896a-ecf76acd4969"
      },
      "source": [
        "#Training the model\n",
        "model.fit(x_train,y_train)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.01, batch_size=230, beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(280,), learning_rate='adaptive',\n",
              "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
              "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
              "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
              "       verbose=False, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30jlmgTiN3km",
        "colab_type": "text"
      },
      "source": [
        "Next we test our model on test_data and see the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rODqbJUdhPe1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "cf9d3e17-60e1-4802-de5f-7b158916f48c"
      },
      "source": [
        "#Predict for the test set\n",
        "y_pred=model.predict(x_test)\n",
        "print(y_pred)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['calm' 'disgust' 'happy' 'happy' 'disgust' 'calm' 'happy' 'happy' 'calm'\n",
            " 'happy' 'happy' 'happy' 'happy' 'happy' 'calm' 'fearful' 'calm' 'happy'\n",
            " 'disgust' 'calm' 'calm' 'fearful' 'calm' 'calm' 'happy' 'calm' 'disgust'\n",
            " 'disgust' 'calm' 'disgust' 'happy' 'disgust' 'happy' 'disgust' 'fearful'\n",
            " 'calm' 'calm' 'fearful' 'calm' 'calm' 'happy' 'disgust' 'calm' 'calm'\n",
            " 'happy' 'calm' 'disgust' 'happy' 'calm' 'fearful' 'happy' 'fearful'\n",
            " 'calm' 'fearful' 'calm' 'calm' 'calm' 'calm' 'calm' 'calm' 'calm' 'calm'\n",
            " 'happy' 'fearful' 'disgust' 'calm' 'calm' 'calm' 'calm' 'calm' 'fearful'\n",
            " 'fearful' 'happy' 'fearful' 'fearful' 'disgust' 'calm' 'happy' 'disgust'\n",
            " 'fearful' 'fearful' 'disgust' 'happy' 'calm' 'fearful' 'calm' 'calm'\n",
            " 'disgust' 'disgust' 'disgust' 'fearful' 'calm' 'calm' 'fearful' 'happy'\n",
            " 'calm' 'calm' 'calm' 'calm' 'disgust' 'fearful' 'calm' 'disgust' 'calm'\n",
            " 'fearful' 'calm' 'happy' 'happy' 'calm' 'fearful' 'fearful' 'fearful'\n",
            " 'calm' 'fearful' 'fearful' 'calm' 'calm' 'fearful' 'calm' 'fearful'\n",
            " 'calm' 'calm' 'calm' 'fearful' 'fearful' 'calm' 'disgust' 'fearful'\n",
            " 'calm' 'calm' 'fearful' 'happy' 'happy' 'disgust' 'calm' 'happy' 'happy'\n",
            " 'calm' 'disgust' 'disgust' 'calm' 'disgust' 'disgust' 'disgust' 'fearful'\n",
            " 'fearful' 'fearful' 'disgust' 'calm' 'calm' 'happy' 'happy' 'happy'\n",
            " 'calm']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9J1qXgrN-7U",
        "colab_type": "text"
      },
      "source": [
        "Now we check its accuracy on our test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUxeNXQnhWXM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c5df65f-f9ea-4866-ee40-7fb61417a8a7"
      },
      "source": [
        "#Calculate the accuracy of our model\n",
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "\n",
        "#Print the accuracy\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 66.23%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OHtOAwWOEio",
        "colab_type": "text"
      },
      "source": [
        "For now its 66.23%. But one can get even better results with few improvsations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oW9IuLOOYYw",
        "colab_type": "text"
      },
      "source": [
        "# THE END"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bG68kmGuttL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}